{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEALTH X - Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents Of Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. import statements\n",
    "2. pulling raw data from data sources\n",
    "3. defining functions for preprocessing \n",
    "4. CNN and CNN + LSTM model for shoulder\n",
    "5. CNN and CNN + LSTM model for finger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed, LSTM, MaxPooling2D, Conv2D, Flatten, Activation,ConvLSTM2D\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12567)\n",
    "seed(109274)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. pulling raw data from data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = pd.read_csv('train_image_paths.csv') # reading training image directories from csv file\n",
    "train_paths.columns = ['image_paths'] # renaming the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image_paths\n",
       "0  MURA-v1.1/train/XR_SHOULDER/patient00001/study...\n",
       "1  MURA-v1.1/train/XR_SHOULDER/patient00001/study...\n",
       "2  MURA-v1.1/train/XR_SHOULDER/patient00002/study...\n",
       "3  MURA-v1.1/train/XR_SHOULDER/patient00002/study...\n",
       "4  MURA-v1.1/train/XR_SHOULDER/patient00002/study..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_paths = pd.read_csv('valid_image_paths.csv') # reading validation image directories from csv file\n",
    "valid_paths.columns = ['image_paths'] # renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MURA-v1.1/valid/XR_WRIST/patient11185/study1_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MURA-v1.1/valid/XR_WRIST/patient11185/study1_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MURA-v1.1/valid/XR_WRIST/patient11185/study1_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MURA-v1.1/valid/XR_WRIST/patient11186/study1_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MURA-v1.1/valid/XR_WRIST/patient11186/study1_p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image_paths\n",
       "0  MURA-v1.1/valid/XR_WRIST/patient11185/study1_p...\n",
       "1  MURA-v1.1/valid/XR_WRIST/patient11185/study1_p...\n",
       "2  MURA-v1.1/valid/XR_WRIST/patient11185/study1_p...\n",
       "3  MURA-v1.1/valid/XR_WRIST/patient11186/study1_p...\n",
       "4  MURA-v1.1/valid/XR_WRIST/patient11186/study1_p..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_paths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. defining functions for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataframe(body_part,t_v): # preparing dataframe for CNN + LSTM\n",
    "    paths = t_v # pandas DataFrame containing all images\n",
    "    paths.columns = ['image_paths'] # renaming column\n",
    "    patient_list = []\n",
    "    file_list = []\n",
    "    for i in paths.image_paths: # looping over each file\n",
    "        if (body_part in i): # get desired body part\n",
    "            patient_num = i.split('/')[3] # get patient number\n",
    "            study_num = i.split('/')[4] # get study number\n",
    "            patient_study = patient_num + '/' + study_num # combining them as patient_number/study_number\n",
    "            patient_list.append(patient_study) # appending patient_number/study_number to list\n",
    "            file_list.append(i) # append file directory to list\n",
    "    dict_dataset = {'patient':patient_list,'file_name':file_list} # combining the two lists into dictionary\n",
    "    df_dataset = pd.DataFrame(dict_dataset) # converting to dataframe\n",
    "    grouped = df_dataset.groupby('patient') # grouping by patient_number/study_number\n",
    "    final_series = grouped['file_name'].unique() # taking unique values\n",
    "    final_dataframe = pd.DataFrame({'patient':final_series.index, 'filename_array':final_series.values})\n",
    "    # getting dataframe with rows in the format: patient_number/study_number  [file1,file2,file3,...]\n",
    "    final_dataframe['filename_string'] = final_dataframe.filename_array.apply(','.join)\n",
    "    # converting file names into string which is comma separated\n",
    "    file_splits = final_dataframe['filename_string'].str.split(',', expand=True)\n",
    "    # splitting on comma creates new column for each file name\n",
    "    patient_files = pd.concat([final_dataframe,file_splits],axis=1)\n",
    "    # concatenate splits with original dataframe\n",
    "    patient_files.drop(columns=['filename_array', 'filename_string'],inplace=True)\n",
    "    # removing unnecessary columns\n",
    "    return(patient_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_cnn(df, part, img_size):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in df.image_paths: # looping over each image\n",
    "        if (part in i): # desired body part\n",
    "            x.append((np.array(cv2.resize(cv2.imread(i),(img_size,img_size))))/255)\n",
    "            # reading image, resizing, normalizing and appending to list\n",
    "            if 'positive' in i:\n",
    "                y.append(1) # assigning labels\n",
    "            else:\n",
    "                y.append(0)\n",
    "    return(np.array(x),np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_df(part):\n",
    "    train = prep_dataframe(part,train_paths) # preprocessing data for CNN + LSTM\n",
    "    train.set_index('patient',inplace=True)\n",
    "    test = prep_dataframe(part,valid_paths) # preprocessing data for CNN + LSTM\n",
    "    test.set_index('patient',inplace=True)\n",
    "    if len(train.columns)>len(test.columns):\n",
    "        # comparing number of columns in training and test data, setting minimum number of columns equal to \n",
    "        # the number of columns for both train and test. This is for performance evaluation\n",
    "        l = len(test.columns)\n",
    "        for i in range((len(train.columns)-len(test.columns))):\n",
    "            test[l+i] = None\n",
    "    elif len(test.columns)>len(train.columns):\n",
    "        l = len(train.columns)\n",
    "        for i in range((len(test.columns))-(len(train.columns))):\n",
    "            train[l+i] = None   \n",
    "    return(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_arr(df,img_size):\n",
    "    zero_pad = [[[0 for k in range(3)] for j in range(img_size)] for i in range(img_size)]\n",
    "    # creating 2D array of zeroes for missing or None images\n",
    "    h = []\n",
    "    for i in df.index:\n",
    "        c = []\n",
    "        for j in df.columns:\n",
    "            if df.loc[i,j]==None:\n",
    "                c.append(np.array(zero_pad))\n",
    "            else:\n",
    "                c.append((np.array(cv2.resize(cv2.imread(df.loc[i,j]),(img_size,img_size))))/255)\n",
    "                # reading image, resizing, normalizing and appending to list\n",
    "        h.append(np.array(c))\n",
    "        c.clear()\n",
    "        \n",
    "    y = []\n",
    "    for i in df.index:\n",
    "        if 'positive' in i: # assigning labels\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "    return(np.array(h),np.array(y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_rnn(part,img_size):\n",
    "    train,test = rnn_df(part) # calling rnn_df internally\n",
    "    x_train, y_train = img_arr(train,img_size) # calling img_arr internally\n",
    "    x_test, y_test = img_arr(test,img_size) # calling img_arr internally\n",
    "    return(x_train,y_train,x_test,y_test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SHOULDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_shoulder,y_train_shoulder = img_cnn(train_paths,'SHOULDER',64)\n",
    "x_test_shoulder, y_test_shoulder = img_cnn(valid_paths,'SHOULDER',64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 62, 62, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 29, 29, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 12, 12, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1000)              577000    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 602,881\n",
      "Trainable params: 602,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn_shoulder = Sequential()\n",
    "model_cnn_shoulder.add(Conv2D(64,(3,3), input_shape=[64,64,3]))\n",
    "model_cnn_shoulder.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model_cnn_shoulder.add(Conv2D(32,(3,3)))\n",
    "model_cnn_shoulder.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model_cnn_shoulder.add(Conv2D(16,(3,3)))\n",
    "model_cnn_shoulder.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model_cnn_shoulder.add(Flatten())\n",
    "model_cnn_shoulder.add(Dense(1000))\n",
    "model_cnn_shoulder.add(Activation('relu'))\n",
    "model_cnn_shoulder.add(Dense(1))\n",
    "model_cnn_shoulder.add(Activation('sigmoid'))\n",
    "\n",
    "model_cnn_shoulder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_shoulder.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8378/8378 [==============================] - 39s 5ms/step - loss: 0.6979 - acc: 0.5127\n",
      "Epoch 2/10\n",
      "8378/8378 [==============================] - 38s 5ms/step - loss: 0.6809 - acc: 0.5654\n",
      "Epoch 3/10\n",
      "8378/8378 [==============================] - 39s 5ms/step - loss: 0.6607 - acc: 0.5992\n",
      "Epoch 4/10\n",
      "8378/8378 [==============================] - 39s 5ms/step - loss: 0.6376 - acc: 0.6364\n",
      "Epoch 5/10\n",
      "8378/8378 [==============================] - 39s 5ms/step - loss: 0.6169 - acc: 0.6576\n",
      "Epoch 6/10\n",
      "8378/8378 [==============================] - 39s 5ms/step - loss: 0.5983 - acc: 0.6799\n",
      "Epoch 7/10\n",
      "8378/8378 [==============================] - 41s 5ms/step - loss: 0.5770 - acc: 0.6950\n",
      "Epoch 8/10\n",
      "8378/8378 [==============================] - 39s 5ms/step - loss: 0.5486 - acc: 0.7205\n",
      "Epoch 9/10\n",
      "8378/8378 [==============================] - 39s 5ms/step - loss: 0.5219 - acc: 0.7403\n",
      "Epoch 10/10\n",
      "8378/8378 [==============================] - 39s 5ms/step - loss: 0.4975 - acc: 0.7527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2090119f9e8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_shoulder.fit(x_train_shoulder,y_train_shoulder,batch_size = 100, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6423304812522806, 0.6589698043005081]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_shoulder.evaluate(x_test_shoulder,y_test_shoulder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + RNN (Time Distributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_shoulder, y_train_shoulder, x_test_shoulder, y_test_shoulder = img_rnn('SHOULDER',64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_11 (TimeDis (None, 11, 62, 62, 64)    1792      \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 11, 31, 31, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 11, 29, 29, 32)    18464     \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 11, 14, 14, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 11, 6272)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               2549200   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,569,557\n",
      "Trainable params: 2,569,557\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "model_mix_shoulder = Sequential()\n",
    "model_mix_shoulder.add(TimeDistributed(Conv2D(64,(3,3),activation='relu'),input_shape=(x_train_shoulder.shape[1],\n",
    "                                                                                        x_train_shoulder.shape[2],\n",
    "                                                                                        x_train_shoulder.shape[3],\n",
    "                                                                                        x_train_shoulder.shape[4])))\n",
    "model_mix_shoulder.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "\n",
    "model_mix_shoulder.add(TimeDistributed(Conv2D(32,(3,3),activation='relu')))\n",
    "#model_mix_shoulder.add(TimeDistributed(Conv2D(128,(3,3),activation='relu')))\n",
    "#model_mix_shoulder.add(TimeDistributed(Conv2D(56,(3,3),activation='relu')))\n",
    "model_mix_shoulder.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "\n",
    "#model_mix_shoulder.add(TimeDistributed(Conv2D(256,(3,3),activation='relu')))\n",
    "#model_mix_shoulder.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "\n",
    "\n",
    "model_mix_shoulder.add(TimeDistributed(Flatten()))\n",
    "\n",
    "#RNN\n",
    "model_mix_shoulder.add(LSTM(100,return_sequences=False))\n",
    "\n",
    "model_mix_shoulder.add(Dense(1))\n",
    "model_mix_shoulder.add(Activation('sigmoid'))\n",
    "\n",
    "model_mix_shoulder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mix_shoulder.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2821/2821 [==============================] - 178s 63ms/step - loss: 0.6940 - acc: 0.5055\n",
      "Epoch 2/10\n",
      "2821/2821 [==============================] - 196s 69ms/step - loss: 0.6933 - acc: 0.5278\n",
      "Epoch 3/10\n",
      "2821/2821 [==============================] - 177s 63ms/step - loss: 0.6926 - acc: 0.5197\n",
      "Epoch 4/10\n",
      "2821/2821 [==============================] - 1014s 360ms/step - loss: 0.6861 - acc: 0.5526\n",
      "Epoch 5/10\n",
      "2821/2821 [==============================] - 177s 63ms/step - loss: 0.6702 - acc: 0.6026\n",
      "Epoch 6/10\n",
      "2821/2821 [==============================] - 174s 62ms/step - loss: 0.6369 - acc: 0.6413\n",
      "Epoch 7/10\n",
      "2821/2821 [==============================] - 174s 62ms/step - loss: 0.6005 - acc: 0.6799\n",
      "Epoch 8/10\n",
      "2821/2821 [==============================] - 178s 63ms/step - loss: 0.5703 - acc: 0.7118\n",
      "Epoch 9/10\n",
      "2821/2821 [==============================] - 750s 266ms/step - loss: 0.5302 - acc: 0.7426\n",
      "Epoch 10/10\n",
      "2821/2821 [==============================] - 177s 63ms/step - loss: 0.4845 - acc: 0.7781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20900385b70>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mix_shoulder.fit(x_train_shoulder,y_train_shoulder,batch_size = 100, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7715888385920181, 0.5618556701030928]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mix_shoulder.evaluate(x_test_shoulder,y_test_shoulder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. FINGER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_finger,y_train_finger = img_cnn(train_paths,'FINGER',64)\n",
    "x_test_finger, y_test_finger = img_cnn(valid_paths,'FINGER',64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(461, 64, 64, 3)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_test_finger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 62, 62, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 29, 29, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 12, 12, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1000)              577000    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 602,881\n",
      "Trainable params: 602,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn_finger = Sequential()\n",
    "model_cnn_finger.add(Conv2D(64,(3,3), input_shape=[64,64,3]))\n",
    "model_cnn_finger.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model_cnn_finger.add(Conv2D(32,(3,3)))\n",
    "model_cnn_finger.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model_cnn_finger.add(Conv2D(16,(3,3)))\n",
    "model_cnn_finger.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model_cnn_finger.add(Flatten())\n",
    "model_cnn_finger.add(Dense(1000))\n",
    "model_cnn_finger.add(Activation('relu'))\n",
    "model_cnn_finger.add(Dense(1))\n",
    "model_cnn_finger.add(Activation('sigmoid'))\n",
    "\n",
    "model_cnn_finger.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_finger.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "5106/5106 [==============================] - 25s 5ms/step - loss: 0.6343 - acc: 0.6265\n",
      "Epoch 2/7\n",
      "5106/5106 [==============================] - 24s 5ms/step - loss: 0.5991 - acc: 0.6588\n",
      "Epoch 3/7\n",
      "5106/5106 [==============================] - 23s 5ms/step - loss: 0.5886 - acc: 0.6547\n",
      "Epoch 4/7\n",
      "5106/5106 [==============================] - 24s 5ms/step - loss: 0.5697 - acc: 0.6849\n",
      "Epoch 5/7\n",
      "5106/5106 [==============================] - 24s 5ms/step - loss: 0.5490 - acc: 0.6980\n",
      "Epoch 6/7\n",
      "5106/5106 [==============================] - 24s 5ms/step - loss: 0.5289 - acc: 0.7237\n",
      "Epoch 7/7\n",
      "5106/5106 [==============================] - 24s 5ms/step - loss: 0.5139 - acc: 0.7346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x229039838d0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_finger.fit(x_train_finger,y_train_finger,batch_size = 100, epochs = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461/461 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6308679375757106, 0.6702819960494879]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_finger.evaluate(x_test_finger,y_test_finger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + RNN (Time distributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_finger, y_train_finger, x_test_finger, y_test_finger = img_rnn('FINGER',32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1935, 6, 32, 32, 3), (1935,), (175, 6, 32, 32, 3), (175,))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train_finger),np.shape(y_train_finger),np.shape(x_test_finger),np.shape(y_test_finger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_32 (TimeDis (None, 6, 30, 30, 64)     1792      \n",
      "_________________________________________________________________\n",
      "time_distributed_33 (TimeDis (None, 6, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_34 (TimeDis (None, 6, 13, 13, 32)     18464     \n",
      "_________________________________________________________________\n",
      "time_distributed_35 (TimeDis (None, 6, 6, 6, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_36 (TimeDis (None, 6, 1152)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               501200    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 521,557\n",
      "Trainable params: 521,557\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "model_mix_finger = Sequential()\n",
    "model_mix_finger.add(TimeDistributed(Conv2D(64,(3,3),activation='relu'),input_shape=(x_train_finger.shape[1],\n",
    "                                                                                        x_train_finger.shape[2],\n",
    "                                                                                        x_train_finger.shape[3],\n",
    "                                                                                        x_train_finger.shape[4])))\n",
    "model_mix_finger.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "\n",
    "model_mix_finger.add(TimeDistributed(Conv2D(32,(3,3),activation='relu')))\n",
    "model_mix_finger.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "\n",
    "model_mix_finger.add(TimeDistributed(Flatten()))\n",
    "\n",
    "#RNN\n",
    "model_mix_finger.add(LSTM(100,return_sequences=False))\n",
    "\n",
    "model_mix_finger.add(Dense(1))\n",
    "model_mix_finger.add(Activation('sigmoid'))\n",
    "\n",
    "model_mix_finger.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mix_finger.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1935/1935 [==============================] - 12s 6ms/step - loss: 0.4782 - acc: 0.7530\n",
      "Epoch 2/10\n",
      "1935/1935 [==============================] - 14s 7ms/step - loss: 0.4671 - acc: 0.7587\n",
      "Epoch 3/10\n",
      "1935/1935 [==============================] - 16s 8ms/step - loss: 0.4695 - acc: 0.7716\n",
      "Epoch 4/10\n",
      "1935/1935 [==============================] - 15s 8ms/step - loss: 0.4368 - acc: 0.7788\n",
      "Epoch 5/10\n",
      "1935/1935 [==============================] - 13s 7ms/step - loss: 0.4266 - acc: 0.7928\n",
      "Epoch 6/10\n",
      "1935/1935 [==============================] - 16s 8ms/step - loss: 0.4061 - acc: 0.8072\n",
      "Epoch 7/10\n",
      "1935/1935 [==============================] - 13s 7ms/step - loss: 0.3661 - acc: 0.8305\n",
      "Epoch 8/10\n",
      "1935/1935 [==============================] - 12s 6ms/step - loss: 0.3544 - acc: 0.8439\n",
      "Epoch 9/10\n",
      "1935/1935 [==============================] - 12s 6ms/step - loss: 0.3196 - acc: 0.8553\n",
      "Epoch 10/10\n",
      "1935/1935 [==============================] - 14s 7ms/step - loss: 0.2893 - acc: 0.8739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2291404d160>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mix_finger.fit(x_train_finger,y_train_finger,batch_size = 100, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8087118411064148, 0.6800000017029898]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mix_finger.evaluate(x_test_finger,y_test_finger)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
